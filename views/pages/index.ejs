<!DOCTYPE html>
<html>
<head>
  <% include ../partials/header.ejs %>
</head>

<!-- set text highlighting to be yellow highlights -->
<style>
mark {
    background-color: yellow;
    color: black;
}
</style>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand" href="#">Kanji App - Kanji Reading Assistance</a>
      </div>
    </nav>
    <!-- Page Content -->
    <div class="container-fluid">

      <!-- Item Heading -->
      <h1 class="mb-3 exception-font">
		  <% if(errors != undefined){ %>
			<% errors.forEach(function(error){ %>
			<div class="alert alert-danger alert-dismissible fade show m-4" role="alert">
				<strong>Error!</strong> <%= error.msg %>
				<button type="button" class="close" data-dismiss="alert" aria-label="Close">
					<span aria-hidden="true">&times;</span>
				</button>
			</div>
			<% }) %>
		  <% } %>
		  
		  <% if(UserImage.textDetections.length > 5 ){ %>
			<div class="alert alert-warning alert-dismissible fade show m-4" role="alert">
				<strong>Warning!</strong> There seems to be a lot of kanji in your image! We may have some trouble providing a good reading.
											Try uploading a simpler image with less kanji to get a better reading.
				<button type="button" class="close" data-dismiss="alert" aria-label="Close">
					<span aria-hidden="true">&times;</span>
				</button>
			</div>
		  <% } %>
      </h1>

      <!-- Item Row -->
      <div class="row">
		<div class="col-md-auto mx-sm-auto my-5">
            <canvas id="myCanvas" width="800" height="800" >
			<img id="image" src="<%= encodeURI(UserImage.filename) %>" />

			</canvas>
        </div>
        <!-- /////Camera install///// -->
			<!--video用于显示媒体设备的视频流，自动播放-->
		<div class="col-md-auto mx-sm-auto my-5">
			<video id="video" autoplay style="width: 480px;height: 320px"></video>
			<!--camera button-->
			<div>
			<button id="capture">Shot!</button>
			</div>
			<!--canvas video snapshot-->
			<canvas id="camera_canvas" width="480" height="320"></canvas>
			<!-- /////Camera install///// -->

        <div class="float-md-right limit-width mx-sm-auto my-5">
			<div class="card border-secondary">
				<div class="card-body">
					<h3 class="card-title">Select an image</h3>
					<!-- Form and Buttons --> 
					<form action="/translate" method="post" enctype="multipart/form-data">
					  <input type="file" name="image" id="fileToUpload" ><br><br>
					  <input type="submit" value="Upload Image" name="submit" class="btn btn-secondary">
				</div>
			</div>

			<div class="card border-secondary">
				<div class="card-body ">
					<h3 class="card-title"> Detected Text </h3>
						<!-- {# <ul class="list-group list-group-flush scroll-box " id="textDetections"> -->
							<!-- <% var detMax = UserImage.textDetections.length %> -->
							<!-- <% var detIdx = 0 %> -->
							<!-- <% while (detIdx < detMax) { %> -->
								<!-- <li class="list-group-item"><%= UserImage.textDetections[detIdx] %> </li> -->
							<!-- <%detIdx=detIdx+1%> -->
							<!-- <%}%> -->
						<!-- </ul> #} -->
						
						<ul class="list-group list-group-flush" id="textDetections">
								<li class="list-group-item"><%= UserImage.textDetections %> </li>
						</ul>
				</div>
			</div>
			
			<div class="card border-secondary">
				<div class="card-body">
					<h3 class="card-title"> Kanji Readings </h3>
					<ul class="list-group list-group-flush" id="textPronunciation">
						<li class="list-group-item"><%= UserImage.textPronunciation %> </li>
					</ul>
				</div>
			</div>
	    </div>

	  </div>

	</div>
    <!-- /.container -->

    <!-- Footer -->
    <footer class="py-4 footer text-faded text-center">
      <div class="container">
        <p class="m-0 text-center text-white">Ai-Network 2018 - CS130</p>
      </div>
      <!-- /.container -->
    </footer>
  
  <!-- draw bounding boxes on image, and set up highlighting -->
  <script>
  
  // 访问用户媒体设备的兼容方法
	function getUserMedia(constrains,success,error){
	    if(navigator.mediaDevices.getUserMedia){
	        //最新标准API
	        navigator.mediaDevices.getUserMedia(constrains).then(success).catch(error);
	    } else if (navigator.webkitGetUserMedia){
	        //webkit内核浏览器
	        navigator.webkitGetUserMedia(constrains).then(success).catch(error);
	    } else if (navigator.mozGetUserMedia){
	        //Firefox浏览器
	        navagator.mozGetUserMedia(constrains).then(success).catch(error);
	    } else if (navigator.getUserMedia){
	        //旧版API
	        navigator.getUserMedia(constrains).then(success).catch(error);
	    }
	}

	var video = document.getElementById("video");
	var canvas = document.getElementById("camera_canvas");
	var context = canvas.getContext("2d");

	//成功的回调函数
	function success(stream){
	    //兼容webkit内核浏览器
	    var CompatibleURL = window.URL || window.webkitURL;
	    //将视频流设置为video元素的源
	    video.src = CompatibleURL.createObjectURL(stream);
	    //播放视频
	    video.play();
	}

	//异常的回调函数
	function error(error){
	    console.log("访问用户媒体设备失败：",error.name,error.message);
	}
	if (navigator.mediaDevices.getUserMedia || navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia){
	    //调用用户媒体设备，访问摄像头
	    getUserMedia({
	        video:{width:480,height:320}
	    },success,error);
	} else {
	    alert("你的浏览器不支持访问用户媒体设备");
	}

	//注册拍照按钮的单击事件
	document.getElementById("capture").addEventListener("click",function(){
	    //绘制画面
	    context.drawImage(video,0,0,480,320);
	});

  window.onload = function() {
  
    //draw rectangles on canvas over bounding boxes
    var c=document.getElementById("myCanvas");
    var ctx=c.getContext("2d");
	var img=document.getElementById("image"); 
	console.log("src front end: " + img.getAttribute("src"));
    ctx.drawImage(img,img.clientWidth,img.clientHeight); 
    console.log("draw"); 

    var canvas = document.getElementById('myCanvas');
    var context = canvas.getContext('2d');
    var box = <%- JSON.stringify(boundingBoxes) %>;
    context.beginPath();
    for (i = 0; i < box.length; i++) {  
	  context.rect(box[i][0].x, box[i][0].y, box[i][2].x - box[i][0].x, box[i][2].y - box[i][0].y)
	  context.fillStyle = "rgba(255, 255, 255, 0)";
	  context.fill();
	  context.lineWidth = 4;
	  context.strokeStyle = "blue";
	  context.stroke();	
	}
	
	//on mouse move, detect if it is over one of the rectangles
	//if it is, then highlight the corresponding texts on the detection and pronunciation
	canvas.onmousemove = function(e) {
	  var rect = this.getBoundingClientRect(),
	    x = e.clientX - rect.left,
		y = e.clientY - rect.top,
		i = 0, r;
		
	  var textDetections = <%- JSON.stringify(UserImage.textDetectionsList) %>;
	  var textPronunciations = <%- JSON.stringify(UserImage.textPronunciationList) %>;

	  for (i = 0; i < box.length; i++) {
	    context.beginPath();
		context.rect(box[i][0].x, box[i][0].y, box[i][2].x - box[i][0].x, box[i][2].y - box[i][0].y)
		if ( context.isPointInPath(x,y)) {
		
		  highlight(textDetections[i], "detections");
		  highlight(textPronunciations[i], "pronounciations");
		}
	  }
	}
	
	//insert a highlight tag into the corresponding innerHTML
	function highlight(text, type) {
	  var inputText;
	  var innerHTML;
	  if (type == "detections"){
		inputText = document.getElementById("textDetections");
		innerHTML = <%- JSON.stringify(UserImage.textDetections) %>;
	  }
	  else if (type == "pronounciations") {
	    inputText = document.getElementById("textPronunciation");
		innerHTML = <%- JSON.stringify(UserImage.textPronunciation) %>;
	  }
	  else {
	    return;
	  }
	  	  
      var index = innerHTML.indexOf(text);
   	  if ( index >= 0 )
      { 
        innerHTML = innerHTML.substring(0,index) + "<mark>" + innerHTML.substring(index,index+text.length) + "</mark>" + innerHTML.substring(index + text.length);
		innerHTML.substring(index + text.length);
        inputText.innerHTML = innerHTML; 
      }
    }
  };


 //  }

</script>
</body>
</html>
